\begin{figure*}[htb!]
    \centering
    \input{figures/results/3d-scalability.pgf}
    \caption{Plot of the run time of \Jajapy\ and \Cupaal\ for the leader sync models, given the number of states and the length of the observations. The planes are linear regression fits to indicate the directions of the trends for the datapoints of similar color.}
    \label{fig:leader_results}
\end{figure*}

\section{Results}\label{sec:results}
In this section, we present the results of our experiments, which are divided into two main parts: the first part focuses on the scalability of \Jajapy\ and \Cupaal\ in terms of time and scalability, while the second part evaluates the accuracy of both tools.

The experiments were conducted on a machine with the specifications and environment listed in \autoref{sec:machine_specs}.


\subsection{Scalability}\label{subsec:scalability}
These results are the time taken to train a model, based on two parameters: the number of states, and the length of the observations in the model increasing.


\begin{table}[htb!]
    \centering
    \caption{Leader Sync model variations in training time in seconds.}
    \label{tab:leader_results}
    \begin{tabular}{lrrrr}
        \toprule
        model & states & length & jajapy (s) & cupaal (s) \\
        \midrule
        3.2   & 26     & 25     & 1.38       & 0.26       \\
        3.2   & 26     & 50     & 1.95       & 0.14       \\
        3.2   & 26     & 100    & 4.09       & 0.23       \\
        3.3   & 69     & 25     & 7.95       & 2.46       \\
        3.3   & 69     & 50     & 11.20      & 1.59       \\
        3.3   & 69     & 100    & 19.65      & 1.75       \\
        3.4   & 147    & 25     & 27.10      & 8.54       \\
        3.4   & 147    & 50     & 42.57      & 9.20       \\
        3.4   & 147    & 100    & 84.02      & 9.90       \\
        4.2   & 61     & 25     & 15.68      & 11.18      \\
        4.2   & 61     & 50     & 24.87      & 13.56      \\
        4.2   & 61     & 100    & 52.11      & 11.24      \\
        4.3   & 274    & 25     & 194.88     & 231.28     \\
        4.3   & 274    & 50     & 414.30     & 379.21     \\
        4.3   & 274    & 100    & 447.83     & 117.78     \\
        4.4   & 812    & 25     & 1846.68    & 3324.83    \\
        4.4   & 812    & 50     & 2290.28    & 1848.44    \\
        4.4   & 812    & 100    & 5652.14    & 3447.56    \\
        5.2   & 141    & 25     & 95.59      & 104.71     \\
        5.2   & 141    & 50     & 342.05     & 553.66     \\
        5.2   & 141    & 100    & 798.73     & 982.97     \\
        5.3   & 1050   & 25     & 4586.86    & 10906.91   \\
        5.3   & 1050   & 50     & 7791.95    & 10405.75   \\
        5.3   & 1050   & 100    & 9821.74    & 5992.51    \\
        \bottomrule
    \end{tabular}
\end{table}


The results for the leader sync model are displayed in \autoref{tab:leader_results} and \autoref{fig:leader_results}, and show the time it takes to train a model, given the number of states and observation length.
Only the training time is considered; the initialization of the programs is not a factor in these numbers.

In \autoref{fig:leader_results}, simple planes are fit with linear regression from the data in \autoref{tab:leader_results}.
This is not an attempt to say anything definitive about the degrees of the scaling, but instead to show the generally observable trend.

Contrary to our expectations, the data does not show a clear difference in the time taken to train the leader sync model between \Jajapy\ and \Cupaal\ for \glspl{dtmc}.

For very small models, the running time does not matter too much, but we observe an initial overhead in \Jajapy\ in comparison to \Cupaal.
This is likely related to the general consensus that Python is a slower language than C in general.

Generally, more states mean longer running time, but interestingly, variations with similar number of states may have very different training times.
The most obvious example is the 3.4 and 5.2 models, with 147 and 141 states respectively.
The 5.2 model is much slower, especially in \Cupaal, showing a \textasciitilde10 times increase in training time, despite having slightly fewer states.

Initially, we only had data for observations of length 25, and the data under those conditions suggested that \Jajapy\ scaled quite a bit better than \Cupaal.

\begin{figure}[htb!]
    \input{figures/results/cupaal-length-to-runtime.pgf}
    \caption{\Cupaal\ runtimes with increasing observation length.}
    \label{fig:cupaal-length-to-runtime}
\end{figure}


\begin{figure}[htb!]
    \input{figures/results/jajapy-length-to-runtime.pgf}
    \caption{\Jajapy\ runtimes with increasing observation length.}
    \label{fig:jajapy-length-to-runtime}
\end{figure}


To explore this behaviour, we extended the experiment to contain data for observations of different lengths, and now our observations are more in line with our expectations.
\Jajapy gets slower at a pace roughly linear with the length of the observations; doubling the observation length doubles the run time of \Jajapy.
This is not the case for \Cupaal, where we do not see any particular increase in running time as the observation length increases.

In fact, looking at \autoref{fig:cupaal-length-to-runtime} and \autoref{fig:jajapy-length-to-runtime}, the \Cupaal\ runtimes look a little strange.


% This is likely due to the smaller size of the model, not having as much redundant calculations to avoid, which is the main advantage of the symbolic approach used in CuPAAL.
% Mention the repeat calculations of a model that has reached a steady-state, and therefore have infinitely repeated observations.
\begin{table}[htb!]
    \centering
    \caption{Leader sync model comparison of the average number of rounds inside. }
    \label{tab:leader-results-accuracy}
    \begin{tabular}{rrrrrrr}
        \toprule
        $\mathcal{M}$ & $|O|$ & rounds & \Jajapy & \Cupaal & $\Delta$ & $\phi$ \\
        \midrule
        3.2           & 25    & 1.33   & 1.28    & 1.28    & 0.00     & 0.04   \\
        3.2           & 75    & 1.33   & 1.30    & 1.30    & 0.00     & 0.02   \\
        3.2           & 100   & 1.33   & 1.28    & 1.28    & 0.00     & 0.04   \\
        3.3           & 25    & 1.12   & 1.23    & 1.23    & 0.00     & 0.09   \\
        3.3           & 50    & 1.12   & 1.11    & 1.11    & 0.00     & 0.01   \\
        3.3           & 100   & 1.12   & 1.13    & 1.13    & 0.00     & 0.00   \\
        3.4           & 25    & 1.07   & 1.08    & 1.08    & 0.00     & 0.01   \\
        3.4           & 50    & 1.07   & 1.09    & 1.09    & 0.00     & 0.02   \\
        3.4           & 100   & 1.07   & 1.11    & 1.11    & 0.00     & 0.04   \\
        4.2           & 25    & 2.00   & 2.11    & 2.12    & -0.00    & 0.06   \\
        4.2           & 50    & 2.00   & 2.16    & 2.16    & 0.00     & 0.08   \\
        4.2           & 100   & 2.00   & 2.00    & 2.00    & 0.00     & 0.00   \\
        4.3           & 25    & 1.35   & 1.37    & 1.37    & 0.00     & 0.01   \\
        4.3           & 50    & 1.35   & 1.28    & 1.28    & 0.00     & 0.05   \\
        4.3           & 100   & 1.35   & 1.25    & 1.25    & 0.00     & 0.07   \\
        4.4           & 25    & 1.19   & 1.25    & 1.25    & 0.00     & 0.05   \\
        4.4           & 50    & 1.19   & 1.17    & 1.17    & 0.00     & 0.01   \\
        4.4           & 100   & 1.19   & 1.27    & 1.27    & 0.00     & 0.07   \\
        5.2           & 25    & 3.20   & 3.27    & 3.27    & -0.00    & 0.02   \\
        5.2           & 50    & 3.20   & 3.06    & 3.06    & -0.00    & 0.04   \\
        5.2           & 100   & 3.20   & 3.50    & 3.50    & 0.00     & 0.09   \\
        5.3           & 25    & 1.35   & 1.32    & 1.32    & 0.00     & 0.02   \\
        5.3           & 50    & 1.35   & 1.27    & 1.27    & 0.00     & 0.06   \\
        5.3           & 100   & 1.35   & 1.33    & 1.33    & 0.00     & 0.01   \\
        \bottomrule
    \end{tabular}
\end{table}


\subsection{Accuracy}\label{subsec:accuracy}
This experiment compares the accuracy of \Cupaal\ and \Jajapy\ in learning the \texttt{Leader Sync} model.
Specifically, we model check how many rounds it takes, for each model to select a new leader, from the original model, \Jajapy\ and \Cupaal\ using properties from \autoref{lst:leader-sync-additions}.

\autoref{tab:leader-results-accuracy} shows the results.
The table includes the number of rounds for the original model (column \textbf{rounds}), and the learned models from \Jajapy, and \Cupaal.
The column $\Delta$ shows the difference between \Cupaal\ and \Jajapy, while $\phi$ shows the relative error between \Jajapy\ and the true value from the original model.

The results show that both \Cupaal\ and \Jajapy\ closely match the true model.
For example, in the row for model 3.2 with 25 observations, the original model takes 1.33 rounds, and both \Cupaal\ and \Jajapy\ predict 1.28 rounds.

In the same row, the difference $\Delta$ is 0.00, meaning the both implementations learned the same model.
The relative error $\phi$ is 0.04, indicating a very small deviation from the true value.
This pattern hold across all models, with \Cupaal\ and \Jajapy\ producing nearly identical results, with only minor differences compared to the true values.

In conclusion, these results show that \Cupaal\ is a reliable and accurate implementation of the \gls{bw} algorithm, matching the performance of \Jajapy\ in learning the model.

\subsection{Extra Scalability}\label{subsec:extra_scalability}
This section will cover the second experiment done for comparing \Cupaal\ and \Jajapy.
This experiment explores the effect of random and semi-random initial model parameters, as we expect repeated values to be highly beneficial for \Cupaal's implementation.

\autoref{tab:leader_results_rand_vs_semi} is the table that compares \Cupaal\ to \Jajapy, and the impact of random and semi-random initialization, in regards to the time needed to learn the model.

Looking at the columns \texttt{rand-ja} and \texttt{semi-ja} which show the impact of random and semi randon initialization for \Jajapy, there is no major impact between the two.
But when looking at the differences for \Cupaal\ it is clear that the semi-random approach is generally faster than the completly random, this becomes especially pronounced as the number of states for the model increase.

We expected this to be the case, as with the number of observations meant more repeated values, the semi random initialization had a similar effect.
This seems to partially aleviate the poor scaling \Cupaal\ suffers from as the number of model states increase.

\begin{table}[htb!]
    \centering
    \caption{Leader Sync model variations in training time with random and semi-random initial values.}
    \label{tab:leader_results_rand_vs_semi}
    \begin{tabular}{rrrrrrrrrrr}
        \toprule
        $\mathcal{M}$ & $|S|$ & $|O|$ & rand-ja & rand-cup & semi-ja & semi-cup \\
        \midrule
        4.2           & 61    & 25    & 15.68   & 11.12    & 13.26   & 7.87     \\
        4.2           & 61    & 50    & 24.87   & 13.56    & 28.32   & 12.54    \\
        4.2           & 61    & 75    & 36.02   & 9.72     & 38.62   & 10.54    \\
        4.2           & 61    & 100   & 52.11   & 11.24    & 53.75   & 10.95    \\
        4.3           & 274   & 25    & 194.88  & 231.28   & 190.65  & 194.04   \\
        4.3           & 274   & 50    & 414.30  & 379.21   & 414.95  & 308.81   \\
        4.3           & 274   & 75    & 476.68  & 232.21   & 486.04  & 206.67   \\
        4.3           & 274   & 100   & 447.83  & 117.78   & 441.40  & 118.17   \\
        4.4           & 812   & 25    & 1846.67 & 3324.83  & 1793.90 & 3087.66  \\
        4.4           & 812   & 50    & 2290.28 & 1848.44  & 2239.18 & 1526.81  \\
        4.4           & 812   & 75    & 3017.72 & 1597.78  & 3177.81 & 1512.33  \\
        4.4           & 812   & 100   & 5652.14 & 3447.56  & 5586.23 & 2959.75  \\
        \bottomrule
    \end{tabular}
\end{table}

Table \autoref{tab:leader_results_loglikelihood}, displays three models with a varrying number og states and observation sequences.
This table is used to highlight that the different methods of initialising model parameters, has an impact of the number of iterations needed, but not showing a clear strength in either method.

This is to be expected, as depending on how close or far off, the values are to the learned model, has an impact on the number of iterations needed.
But it also showcases that there is no impact on the loglikelihood, meaning that no matter the method used the model learned is still equally close to the correct model.

\begin{table}[htb!]
    \centering
    \caption{Leader Sync model variations in loglikelihood for random and semi-random initial values.}
    \label{tab:leader_results_loglikelihood}
    \begin{tabular}{rrrrrrrrrrr}
        \toprule
        $\mathcal{M}$ & $|S|$ & $|O|$ & iter(rand) & iter(semi) & $\ell$ rand & $\ell$ semi \\
        \midrule
        4.2           & 61    & 25    & 18         & 16         & -140.41     & -140.41     \\
        4.2           & 61    & 50    & 17         & 20         & -149.13     & -149.13     \\
        4.2           & 61    & 75    & 17         & 18         & -117.80     & -117.80     \\
        4.2           & 61    & 100   & 17         & 18         & -138.63     & -138.63     \\
        4.3           & 274   & 25    & 18         & 18         & -79.92      & -79.92      \\
        4.3           & 274   & 50    & 18         & 18         & -67.24      & -67.25      \\
        4.3           & 274   & 75    & 18         & 18         & -65.71      & -65.71      \\
        4.3           & 274   & 100   & 18         & 18         & -62.55      & -62.55      \\
        4.4           & 812   & 25    & 18         & 18         & -62.55      & -62.55      \\
        4.4           & 812   & 50    & 18         & 18         & -48.49      & -48.49      \\
        4.4           & 812   & 75    & 17         & 18         & -52.26      & -52.26      \\
        4.4           & 812   & 100   & 18         & 18         & -65.71      & -65.71      \\
        \bottomrule
    \end{tabular}
\end{table}



\begin{figure}[htb!]
    \input{figures/experiment3/model4.2semirandom-cupaal-jajapy-runtime.pgf}
    \caption{Model 4.2 - Runtime for random and semi-random}
    \label{fig:semirandom-cupaal-jajapy-4-2}
\end{figure}

\begin{figure}[htb!]
    \input{figures/experiment3/model4.3semirandom-cupaal-jajapy-runtime.pgf}
    \caption{Model 4.3 - Runtime for random and semi-random}
    \label{fig:semirandom-cupaal-jajapy-4-3}
\end{figure}

\begin{figure}[htb!]
    \input{figures/experiment3/model4.4semirandom-cupaal-jajapy-runtime.pgf}
    \caption{Model 4.4 - Runtime for random and semi-random}
    \label{fig:semirandom-cupaal-jajapy-4-4}
\end{figure}

Figures \autoref{fig:semirandom-cupaal-jajapy-4-2} \autoref{fig:semirandom-cupaal-jajapy-4-3} \autoref{fig:semirandom-cupaal-jajapy-4-4} give a visual representation of how \Cupaal\ compares to \Jajapy based on the observation counts while using both random and semi-random initialization.

These graphs showcase the general trend of \Cupaal\ performing slightly better with a semi-random initialization, where for \Jajapy\ we observe there is no clear tendency for what performes best.

Table \autoref{tab:experiment3-table} shows the seconds pr iteration to compute, for \Cupaal\ and \Jajapy\ for both random and semi-random initialization.
\Jajapy\ is not noticable affected by either method, giving a gain of about $1\%$ when using the semi-random initialization over the random approach, this can be explained by coinsidence as the differences is negligable.
\Cupaal\ does have a slight gain when using the semi-random approach, showcasing a gain of $\sim 11\%$ less time needed pr. iteration compared to the completly random approach.

These results seem to indicate a gain for \Cupaal\ when there are repeated values for the initialization.
This lines up well with our hypothesis that \Cupaal\ performs better when it can leverage repeated values for it's \gls{add} structure.

\begin{table*}[htb!]
    \caption{Experiment three results}
    \label{tab:experiment3-table}
    \begin{tabular}{rrrrrrrrrrrrrrrr}
        \toprule
        $\mathcal{M}$ & $|O|$ & i ran & i semi & s ran-ja & s ran-cup & s semi-ja & s semi-cup & $\ell$ ran & $\ell$ semi & s/i ran-ja & s/i semi ja & s/i ran-cup & s/i semi-cup & ja change & cup change \\
        \midrule
        4.2           & 25    & 18    & 16     & 15.68    & 11.12     & 13.26     & 7.87       & -140.41    & -140.41     & 0.87       & 0.83        & 0.62        & 0.49         & -4.87     & -20.34     \\
        4.2           & 50    & 17    & 20     & 24.87    & 13.56     & 28.32     & 12.54      & -149.13    & -149.13     & 1.46       & 1.42        & 0.80        & 0.63         & -3.21     & -21.41     \\
        4.2           & 75    & 17    & 18     & 36.02    & 9.72      & 38.62     & 10.54      & -117.80    & -117.80     & 2.12       & 2.15        & 0.57        & 0.59         & 1.27      & 2.41       \\
        4.2           & 100   & 17    & 18     & 52.11    & 11.24     & 53.75     & 10.95      & -138.63    & -138.63     & 3.07       & 2.99        & 0.66        & 0.61         & -2.58     & -8.04      \\
        4.3           & 25    & 18    & 18     & 194.88   & 231.28    & 190.65    & 194.04     & -79.92     & -79.92      & 10.83      & 10.59       & 12.85       & 10.78        & -2.17     & -16.10     \\
        4.3           & 50    & 18    & 18     & 414.30   & 379.21    & 414.95    & 308.81     & -67.24     & -67.25      & 23.02      & 23.05       & 21.07       & 17.16        & 0.16      & -18.56     \\
        4.3           & 75    & 18    & 18     & 476.68   & 232.21    & 486.04    & 206.67     & -65.71     & -65.71      & 26.48      & 27.00       & 12.90       & 11.48        & 1.96      & -11.00     \\
        4.3           & 100   & 18    & 18     & 447.83   & 117.78    & 441.40    & 118.17     & -62.55     & -62.55      & 24.88      & 24.52       & 6.54        & 6.57         & -1.44     & 0.33       \\
        4.4           & 25    & 18    & 18     & 1846.67  & 3324.83   & 1793.90   & 3087.66    & -62.55     & -62.55      & 102.59     & 99.66       & 184.71      & 171.54       & -2.86     & -7.13      \\
        4.4           & 50    & 18    & 18     & 2290.28  & 1848.44   & 2239.18   & 1526.81    & -48.49     & -48.49      & 127.24     & 124.40      & 102.69      & 84.82        & -2.23     & -17.40     \\
        4.4           & 75    & 17    & 18     & 3017.72  & 1597.78   & 3177.81   & 1512.33    & -52.26     & -52.26      & 177.51     & 176.54      & 93.99       & 84.02        & -0.55     & -10.61     \\
        4.4           & 100   & 18    & 18     & 5652.14  & 3447.56   & 5586.23   & 2959.75    & -65.71     & -65.71      & 314.01     & 310.35      & 191.53      & 164.43       & -1.17     & -14.15     \\
        \bottomrule
    \end{tabular}
\end{table*}
