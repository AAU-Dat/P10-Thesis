\section{Preliminaries}\label{sec:preliminaries}
This section provides an overview of the theoretical background necessary to understand the rest of the article.
We begin by defining the key concepts of a \gls{hmm} and a \gls{mc}, which are the two main models used in this report.


\subsection{Hidden Markov Model}\label{subsec:hmm}
\glspl{hmm} were introduced by Baum and Petrie in 1966~\cite{baum1966statistical} and have since been widely used in various fields, such as speech recognition~\cite{chavan2013overview}, bioinformatics~\cite{ciocchetta2009bio}, and finance~\cite{mamon2007hidden}.
\begin{definition}[Hidden Markov Model]
    A Hidden Markov Model (HMM) is a tuple $\mathcal{M} = (S, \mathcal{L}, \mathscr{l}, \tau,  \pi)$, where:
    \begin{itemize}
        \item $S$ is a finite set of states.
        \item $\mathcal{L}$ is a finite set of labels.
        \item $\mathscr{l}: S \rightarrow D(\mathcal{L})$ is the emission function.
        \item $\tau: S \rightarrow D(S)$ is the transition function.
        \item $\pi \in D(S)$ is the initial distribution.
    \end{itemize}
\end{definition}

$D(X)$ denotes the set of probability distributions over a  finite set $X$.
The emission function $\mathscr{l}$ describes the probability of emitting a label given a state.
The transition function $\tau$ describes the probability of transitioning from one state to another.
The initial distribution $\pi$ describes the probability of starting in a given state.
An \gls{hmm} is a statistical model that describes a system that evolves over time.
The system is assumed to hold the Markov property, meaning that the future state of the system only depends on the current state and not on the past states.
The system is also assumed to be unobservable, meaning that the states are hidden and cannot be directly observed.
Instead, the system emits observations, which are used to infer the hidden states.

An example of an \gls{hmm} is a weather model where the hidden state represents the actual weather (sunny, rainy, or cloudy), but we only observe indirect signals, such as whether someone is carrying an umbrella.

\subsection{Markov Chain}\label{subsec:mc}
A \gls{mc}, named after Andrei Markov, is a stochastic model widely used in different fields of study~\cite{Rabiner89}.
\begin{definition}[Markov Chain]
    A Markov Chain (MC) is a tuple $\mathcal{M} = (S, \mathcal{L}, \mathscr{l}, \tau,  \pi)$ identical to the HMM structure above except that the emission function is
    \emph{deterministic}: for every $s\in S$ there is a single label
    $l=\mathscr{l}(s)$ emitted with probability 1.
\end{definition}
In other words, the emission function $\mathscr{l}$ is a one-to-one mapping from states to labels.

A common example of an MC is a board game where a player moves between squares based on dice rolls.
Each square corresponds to a state, the dice rolls determine the transition probabilities, and the current square (state) is directly observable.

\subsection{Conversion between MCs and HMMs}\label{subsec:mc_hmm_conversion}
In this section, we will discuss the conversion between \glspl{mc} and \glspl{hmm}.
This conversion is important because it allows us to use the same algorithms and techniques for both models, even though they have different properties.
From the definition of a \gls{mc}, we can see that it is a special case of an \gls{hmm} where the emission function is deterministic.

\subsubsection{Markov Chains to Hidden Markov Models}\label{subsec:mc2hmm}
This conversion is straightforward because the components of the \gls{mc} and \gls{hmm} are the same.
\begin{definition}[Markov Chain to Hidden Markov Model]
    Given a \gls{hmm} $\mathcal{M} = (S, \mathcal{L}, \mathscr{l}, \tau,  \pi)$, we can convert it into a \gls{mc} $\mathcal{M}' = (S', \mathcal{L}', \mathscr{l}', \tau',  \pi')$ by defining the components as follows:
    \begin{itemize}
        \item $S' = S$.
        \item $\mathcal{L}' = \mathcal{L}$.
        \item $\mathscr{l}' =  \begin{cases}
                      1 & l=\mathscr{l}(s) \\
                      0 & \text{otherwise}
                  \end{cases}$
        \item $\tau' = \tau$.
        \item $\pi' = \pi$.
    \end{itemize}
\end{definition}
The \gls{mc} $\mathcal{M}'$ is equivalent to the \gls{hmm} $\mathcal{M}$, meaning that they have the same transition and emission probabilities.
The only difference is that the \gls{mc} has a trivial emission function, meaning that each state emits a single label with probability 1.

\subsubsection{Hidden Markov Models to Markov Chains}\label{subsec:hmm2mc}
Converting a \gls{hmm} to an equivalent \gls{mc} is more complex.
In a \gls{hmm}, the observations are probabilistically related to the states, which introduces ambiguity, as multiple states can emit the same observation.
To create a fully observable \gls{mc} that captures the behavior of a \gls{hmm}, we must encode both the hidden state and the emitted label into the state space.
\begin{definition}[Hidden Markov Model to Markov Chain]
    Conversely, let
    \(
    \mathcal{M}
    = (S, \mathcal{L}, \mathscr{l}, \tau, \pi)
    \)
    be a \gls{hmm}.
    We define the observable \gls{mc}
    \(
    \mathcal{M}'
    = (S', \mathcal{L}', \mathscr{l}', \tau', \pi')
    \)
    by:
    \begin{itemize}
        \item $S' = \{(s,l)\in S\times\mathcal{L}\}$%, the new state space encodes both hidden states and their possible emitted labels,
        \item $\mathcal{L}' = \mathcal{L}$%, the label space remains unchanged,
        \item $\mathscr{l}'(s,l) = l$%, each new state deterministically emits its label,
        \item $\tau'\big((s,l),(s',l')\big) = \tau(s,s')\;\mathscr{l}(s')(l')$%, the transition function is modified to account for the emission probabilities,
        \item $\pi'(s,l) = \pi(s)\;\mathscr{l}(s)(l)$%, the initial distribution is modified to account for the emission probabilities.
    \end{itemize}
    \textbf{Remark.}
    Here each ' symbol refers to an object of the \emph{derived MC}.  In
    particular, $\tau'$ is \emph{not} the original HMM transition; it acts on the
    expanded state space $S'$ and already incorporates the emission probability for
    the label $l'$.

    The mapping increases the state space size from $|S|$ to at most
    $|S|\cdot|\mathcal{L}|$, but yields a fully observable system amenable to
    standard MC analysis.
\end{definition}

The conversion between \glspl{mc} and \glspl{hmm} is important because it allows us to use the same algorithms and techniques for both models, even though they have different properties.

\subsection{Baum-Welch Algorithm}\label{subsec:baum-welch}
The Baum-Welch algorithm is a special case of the Expectation-Maximization (EM) framework used to estimate the parameters of a Hidden Markov Model (HMM) given a set of observed sequences. Since the underlying states are not directly observable, the algorithm iteratively refines the model parameters $\pi$, $\mathscr{l}$, and $\tau$ to maximize the likelihood of the observations.
Each iteration of the algorithm consists of two steps:
\begin{itemize}
    \item E-step: Compute the expected values of the hidden variables (state transitions and state occupancies) given the current parameters.
    \item M-step: Update the model parameters to maximize the expected complete-data log-likelihood.
\end{itemize}

Convergence is typically achieved when the change in the likelihood (or parameters) between iterations falls below a threshold~\cite{Rabiner89}.

We adopt a matrix-based implementation for computational efficiency, following~\cite{aaholmbaum}, and extend it to handle multiple observation sequences. Notation used throughout this section is summarized below:
\begin{itemize}
    \item $|S|$ is the number of hidden states.
    \item $|\mathcal{L}|$ is the number of labels.
    \item $\mathcal{O} = {O_1, \ldots, O_{|\mathcal{O}|}}$  is the set of observations sequences.
    \item Each observation sequence $O_i = (o_{i1}, o_{i2}, \ldots, o_{i|o|-1 })$, where $o_{it} \in \mathcal{L}$.
    \item $s_t$ is the hidden state at time $t$.
    \item $|O|$ is the number of observation sequences.
    \item $|\mathbf{o}|$ is the length of a single observation sequence.
    \item $o_t$ is the observation at time $t$.
    \item $s_t$ is the state at time $t$.
\end{itemize}

We can represent a HMM as matrices for computational efficiency.
They are defined as follows:
\begin{itemize}
    \item $\pmb{\pi}$ is the initial state distribution vector, where $\pi_i = \pi(s_i)$ is the probability of starting in state $s_i$, this is a column vector of size $|S|$.
    \item $\pmb{P}$ is the transition matrix, where $P_{ij} = \tau(s_i)(s_j)$ is the probability of transitioning from state $s_i$ to state $s_j$, this is a square matrix of size $|S| \times |S|$.
    \item $\pmb{\omega}$ is the emission matrix, where $\omega_{ij} = \mathscr{l}(s_i)(l_j)$ is the probability of emitting label $l_j$ given state $s_i$, this is a matrix of size $|S| \times |\mathcal{L}|$.
\end{itemize}

We describe observations as a sequence of labels $O = (o_1, o_2, \ldots, o_{|o|-1})$, where $o_t \in \mathcal{L}$.
We can describe multiple sequences as a set of observations $\mathcal{O} = \{O_1, O_2, \ldots, O_{|O|-1}\}$, where $O_i = (o_{i1}, o_{i2}, \ldots, o_{i|o|-1})$.

We follow a matrix-based implementation for computational efficiency, as described in~\cite{aaholmbaum}, and extend it to handle multiple observation sequences.

Using multiple sequences, we dont need to change the calculation of the E-step, as it is the same as before, we just need to do it for every observation sequence.
In the M-step, we need to update the parameters based on all the observation sequences.
We dont need to change the calculation of $\gamma$ and $\xi$, we just need to cacalate for every observation sequence.

We get from \cite{aaholmbaum} that the update equations for the parameters are as follows:
\begin{equation}
    \pmb{P}_{s s'} = \frac{\sum_{t = 1}^{|\mathbf{o}|-1} \xi_{ss'}(t)}{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t)}
    \label{eq:transition-probabilities}
\end{equation}

\begin{equation}
    \pmb{\omega}_{s, l} = \frac{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t) \lBrack o_t = l \rBrack}{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t)}
    \label{eq:omega}
\end{equation}

\begin{equation}
    \pi_s = \gamma_s(1)
    \label{eq:initial-probabilities}
\end{equation}

We can then update the parameters for a single sequence with matrix operations as follows:

\begin{equation}
    \pmb{P}
    = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet \pmb{\xi}
    \label{eq:transition-probabilities-multiple-sequences}
\end{equation}

\begin{equation}
    \pmb{\omega}
    _s(o) = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet (\sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_t \otimes \mathbbm{1}_{yt}^{|\mathbf{o}|-1})
    \label{eq:omega-multiple-sequences}
\end{equation}

\begin{equation}
    \pmb{\pi}
    = \pmb{\gamma}_1
    \label{eq:initial-probabilities-multiple-sequences}
\end{equation}

Here $\oslash$ denotes Hadamard division (elementwise division) and $\bullet$ denotes the Katri-Rao product (column-wise Kronecker product).
In the formulas above, $\mathbbm{1}$ denotes a column vector of ones, $\mathbbm{1}_{yt}$ denotes a column vector with $|\mathcal{L}|$ rows, with all elements set to zero except for the element at the index where $o_t = l$ which is set to one.

$\gamma$ and $\xi$ are the sum of the respective vectors over all time steps $t$:
\begin{align}
    \pmb{\gamma} = \sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_t
    \text{ and }
    \pmb{\xi} = \sum_{t=1}^{|\mathbf{o}|-1} \pmb{\xi}_t
\end{align}

Now we can extend this to multiple sequences.
We can see that the update equations for the parameters are the same as before, but we need to sum over all sequences and all time steps.

\begin{equation}
    \pi_s = \frac{\sum_{i=i}^{|\mathcal{O}|} \gamma_{is}(1) }{|\mathcal{O}|}
\end{equation}

\begin{equation}
    \pmb{\omega}_{s, l} = \frac{\sum_{i=1}^{|\mathcal{O}|} \sum_{t=1}^{|\mathbf{o}|-1} \gamma_{is}(t) \lBrack o_t = l \rBrack}{\sum_{i=1}^{|\mathcal{O}|} \sum_{t=1}^{|\mathbf{o}|-1} \gamma_{is}(t)}
\end{equation}

\begin{equation}
    \pmb{P}_{s s'} = \frac{\sum_{i=1}^{|\mathcal{O}|} \sum_{t = 1}^{|\mathbf{o}|-1} \xi_{iss'}(t)}{\sum_{i=1}^{|\mathcal{O}|} \sum_{t = 1}^{|\mathbf{o}|-1} \gamma_{is}(t)}
\end{equation}

In the transition matrix, we need to sum over all sequences and all time steps.
In the initial distribution, we need to sum over all sequences and take the first time step.
In the emission matrix, we need to sum over all sequences and all time steps.

This means, when describing the update equations as matrix operations, we need to sum over all sequences and all time steps, when calculating the $\gamma$ and $\xi$ matrices.

we need to find the sum of the $\gamma$ and $\xi$ over all sequences and all time steps.

This will give us:

\begin{align}
    \pmb{\gamma} = \sum_{i=1}^{|\mathcal{O}|}\sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_t
    \text{ and }
    \pmb{\xi} = \sum_{i=1}^{|\mathcal{O}|}\sum_{t=1}^{|\mathbf{o}|-1} \pmb{\xi}_t
\end{align}

We can then update the parameters with matrix operations as follows:
\begin{equation}
    \pmb{P}
    = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet \pmb{\xi}
    \label{eq:transition-probabilities-update}
\end{equation}

This is the same as the previous equation, but we need to sum over all sequences and all time steps.

\begin{equation}
    \pmb{\omega}
    _s(o) = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet (\sum_{i=1}^N \sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_{it} \otimes \mathbbm{1}_{yt}^{|\mathbf{o}|-1})
    \label{eq:omega-update}
\end{equation}
This is almost the same as the previous equation, but we need to sum over all sequences and all time steps, in the left side of the Kronecker product, the right side is the same as before.

\begin{equation}
    \pmb{\pi}
    = \pmb{\gamma}_1
    \label{eq:initial-probabilities-update}
\end{equation}
This is the same as the previous equation, but we need to sum over all sequences and all time steps.


