\section{Discussion}\label{sec:discussion}
In this section, we discuss the results presented in \autoref{sec:results} and reflect on the performance of \Cupaal\ compared to \Jajapy.

The results presented in \autoref{subsec:accuracy} confirm that \Cupaal\ and \Jajapy\ learn identical models, which is expected as the \gls{bw} algorithm should be the same despite the different technical implementations.
Both reach the same model in the same number of iterations, with identical log-likelihood and accuracy, as confirmed by model checking with properties, which establishes their computational equivalence and provides a solid foundation for further work with symbolic implementations.

Unfortunately, the scalability results from \Cref{subsec:scalability,subsec:controled_initialization} do not show \Cupaal\ to be as clear a winner as we had expected.
There are benefits to a symbolic calculation, but they are not as pronounced as previous work suggested in work done for implementations targeting only the forward-backward procedure.

The theoretical advantage of matrices with a lot of repeated values represented as \glspl{add} is confirmed, as seen by the results in \autoref{subsec:controled_initialization}, and there may be even more performance to be gained with different symbolic implementations.
Currently, \Cupaal\ cleans up after each iteration, which may generally improve or worsen performance; however, we expect it to worsen performance in cases with a high number of repeat values.

The experiment is conducted using a single model, leader sync, which may not provide a comprehensive view of performance across different scenarios.
A more effective approach would have been to utilize multiple models with varying characteristics and compare their performance, which would allow for a more comprehensive overview of \Cupaal's scalability compared to \Jajapy.

Other models that were considered were the \gls{nand} and \gls{brp} models, also from the qcomp benchmark set~\cite{hartmanns2019quantitative}.
A wider variety of models would provide more and clearer insight into \Cupaal, thereby displaying its strengths and weaknesses more completely.

The model could also have utilized a greater number of states and observations; currently, the largest model contains 1,050 states and observation sequences of length 100.

Larger models were considered, but it was determined that the largest model used was sufficient, given the time required for learning.

We ran the experiments in a Docker container, which introduces some level of overhead.
We have not investigated whether this overhead introduces any bias towards \Jajapy\ or \Cupaal.
While we do not expect it to do so, we also cannot say that we fully understand the overhead of Docker.
For completeness, this might have been better explored.

In \autoref{sec:exp_extra_scalability}, the values for the initial model values are not entirely random. Instead, they are designed to have repeated values, which was done to display the theoretical strengths of \Cupaal.
This method skews the model to favor \Cupaal, as the \gls{add} structure benefits from repeated values and, therefore, will display results that indicate \Cupaal\ as the stronger implementation.

This was done purely to research what was believed to be a strength of \Cupaal\ and to further the discussion on when \Cupaal\ is a good option to use over other tools, such as \Jajapy.
It would be interesting to explore the limits of this initialization strategy for the \gls{bw} algorithm in general, as initialization of the \gls{sul} is a point of research on its own.


\subsection{Implementation Discussion}\label{subsec:implementation_discussion}
The integration of \Cupaal\ into \Jajapy\ has been successful, allowing us to leverage the \gls{bw} algorithm for parameter estimation for \glspl{hmm} and \glspl{mc}.

The decision to use pybind11 for creating bindings between C++ and Python has proven effective, as it allows us to easily call C++ functions from Python.

The exact implementation of the symbolic fit function in \Jajapy, shown in~\autoref{lst:jajapy-fit-cupaal}, is to be discussed with the \Jajapy\ creator, and in the final integration into \Jajapy\ some changes are expected to be made.

\Cupaal\ displays clear benefits when working with repeated values; however, it did not compare as favorably to \Jajapy\ as we expected.

Previous work indicated that \Cupaal\ overall was a stronger implementation, but with an entirely symbolic implementation, some potential bottlenecks have been observed.

Specifically in the update step of the \gls{bw} algorithm, as when working with \glspl{add} for just the $\alpha$ and $\beta$ steps, \Cupaal\ performed very well - much better than what is indicated for the complete \gls{bw} algorithm implemented here.

This suggests that there may be issues when updating the values when using \glspl{add}.
To further research this topic, a hybrid implementation could be provided.
This implementation would utilize \glspl{add} when calculating $\alpha$ and $\beta$ and then employ a recursive approach when updating values.

An implementation like this would require much conversion between matrices and \glspl{add}, but comparing a fully symbolic, a recursive, and a hybrid approach would give further insight into what \Cupaal\ struggles with.

For now, \Cupaal\ only measures the time taken to compute the \gls{bw} algorithm, but an interesting metric to compare would be the memory used.
If \Cupaal\ was discovered to require less memory than \Jajapy, even with more time needed for larger models, it could be a better choice in situations where memory was a constraint.
However, without a memory metric to compare, the decision can only be made based on the time required for computing \gls{bw}.

The library used to manipulate \glspl{add} was \gls{cudd}, as it was what previous work had built upon.
A discussion at the time also raised the question of whether this is the best tool for the job, as other tools, such as Sylvan~\cite{van2017sylvan}, exist.
This discussion remains relevant and worth exploring, especially in the context of parallelization, which is not possible in the current implementation of \Cupaal.

\Cupaal\ is designed for the \gls{bw} algorithm, but it is worth exploring other algorithms that could benefit from a symbolic implementation.
An algorithm that could be explored could be the Viterbi algorithm.
By exploring other algorithms, the general benefits of using a symbolic approach can be better understood.


\subsection{Future Work}\label{subsec:future_work}
This section will discuss areas that might be worth exploring in future work.

\Cupaal\ only utilizes a single core. This is not an issue when comparing it to \Jajapy, as it can be limited to using only a single core as well.
However, improving \Cupaal\ to support multiple cores could be a worthwhile direction to explore, as it could provide a significant performance increase.

In a multiset of observation sequences, sequences are grouped if they are identical, meaning that when computing these observation sequences, we can factor in the number of identical sequences and only compute the $\alpha$ and $\beta$ values once for the same sequence.

Expanding upon this idea involves utilizing prefixes and suffixes to enhance observations.
Many observations may not be entirely identical, but they could share a significant number of labels.

To leverage this, prefixes and suffixes of observations could be considered and grouped as is done currently.
Given that an observation sequence contains many observations that share prefixes and suffixes of labels, effectively building a tree structure of prefixes/suffixes.
The gain could prove to be significant.

In the update step of \gls{bw} in \Cupaal, consideration is not made to check if the model worked on is a \gls{mc}.
This might be worth adding, as in these cases, unnecessary computation is made, as \glspl{mc} do not require the $\omega$ function to be updated.

This is a minor consideration, as these values are ignored after they are computed, but it could be worth implementing.
